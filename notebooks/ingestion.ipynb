{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion\n",
    "\n",
    "Source: https://www1.ncdc.noaa.gov/pub/data/noaa/isd-lite/\n",
    "\n",
    "Description: https://www1.ncdc.noaa.gov/pub/data/noaa/isd-lite/isd-lite-format.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.delayed import delayed\n",
    "from dask import compute\n",
    "from dask.distributed import Client, progress\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_URL = \"https://www1.ncdc.noaa.gov/pub/data/noaa/isd-lite/\"\n",
    "STATIONS = (\"722430-12960\", )\n",
    "YEARS = range(2022,1980, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_url(year, station):\n",
    "    file=f\"{station}-{year}.gz\"\n",
    "    url = f\"{ROOT_URL}{year}/{file}\"\n",
    "    return url\n",
    "    \n",
    "source_url = get_source_url(2021, \"722430-12960\")\n",
    "source_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_filename(year, station):\n",
    "    file=f\"{station}-{year}.gz\"\n",
    "    url = f\"{ROOT_URL}{year}/{file}\"\n",
    "    filename = f'../data/{year}/{file}'\n",
    "    return filename\n",
    "target_filename = get_target_filename(2021, \"722430-12960\")\n",
    "target_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest(source_url, target_filename):\n",
    "    if os.path.exists(target_filename):\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(os.path.dirname(target_filename)):\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(target_filename))\n",
    "        except OSError as exc: # Guard against race condition\n",
    "            pass\n",
    "            # if exc.errno != errno.EEXIST:\n",
    "                # raise\n",
    "    r = requests.get(source_url, allow_redirects=True)\n",
    "    if r.status_code==200:\n",
    "        open(target_filename, 'wb').write(r.content)            \n",
    "\n",
    "ingest(source_url, target_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_urls=[]\n",
    "target_filenames=[]\n",
    "\n",
    "for year in YEARS:\n",
    "    for station in STATIONS:\n",
    "        source_urls.append(get_source_url(year, station))\n",
    "        target_filenames.append(get_target_filename(year, station))\n",
    "        \n",
    "source_urls[0:3], target_filenames[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source_url, target_filename in zip(source_urls, target_filenames):\n",
    "    ingest(source_url, target_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_filenames = glob.glob(\"../data/*/*.gz\", recursive=True)\n",
    "target_filenames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "def read_csv(filename):\n",
    "    return pd.read_csv(filename, header=None)\n",
    "\n",
    "raw_dfs = [delayed(read_csv)(fn) for fn in target_filenames]\n",
    "raw_df = dd.from_delayed(raw_dfs) # df is a dask dataframe\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year=raw_df[0].str[0:4].astype(int)\n",
    "month=raw_df[0].str[6:7].astype(int)\n",
    "day=raw_df[0].str[9:11].astype(int)\n",
    "hour=raw_df[0].str[12:13].astype(int)\n",
    "\n",
    "temperature=raw_df[0].str[14:19].astype(float).replace(-9999, pd.NA)/10\n",
    "dewpoint=raw_df[0].str[20:24].astype(float).replace(-9999, pd.NA)/10\n",
    "pressure=raw_df[0].str[26:31].astype(float).replace(-9999, pd.NA)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressure.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(zip(year, month, day, hour, temperature, dewpoint, pressure), columns=[\"year\", \"month\", \"hour\", \"day\", \"temperature\", \"dewpoint\", \"pressure\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
